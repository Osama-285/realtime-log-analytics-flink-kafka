# Real-Time Log Analytics & Incident Detection System

## ğŸ“Œ Overview

This project implements a **real-time incident detection and analytics platform** using **Apache Kafka, Apache Flink, and Spark Structured Streaming**.

The system ingests streaming alerts from Kafka, performs **stateful incident escalation** using Flink, and computes **window-based operational metrics** using Spark for real-time observability and monitoring.

---

## ğŸ— Architecture

```
Producers (Logs / Metrics)
        |
        v
   Kafka (incident_alerts)
        |
        |-------------------------------|
        |                               |
        v                               v
 Apache Flink                    Spark Structured Streaming
 (Stateful Escalation)           (Windowed Aggregations)
        |                               |
        v                               v
 Kafka (incident_escalations)     Aggregated Metrics Output
```

---

## ğŸ”§ Tech Stack

* **Apache Kafka (Confluent)** â€“ Real-time event streaming backbone
* **Apache Flink (PyFlink)** â€“ Stateful stream processing & incident escalation
* **Spark Structured Streaming** â€“ Windowed aggregations & analytics
* **Python** â€“ Stream processing logic
* **Event-Time Processing** â€“ Watermarks & late data handling

---

## ğŸš¨ Flink: Stateful Incident Escalation

### Key Features

* Keyed by `service`
* Maintains **alert count per service** using Flink managed state
* Uses **State TTL (1 hour)** to avoid unbounded state growth
* Automatically **escalates incidents** after multiple alerts

### Example Escalation Logic

* If **3 alerts** occur for the same service:

  * Severity escalated to `ESCALATED`
  * Event published to `incident_escalations` Kafka topic

---

## ğŸ“Š Spark: Windowed Streaming Analytics

### Implemented Metrics

* **1-minute tumbling windows**
* **Event-time processing with watermarks**
* Metrics computed per service:

  * Total alerts / escalations
  * P95 latency averages
  * Error rate spikes
  * Breach counts
  * Critical incident ratio

### Output Use Cases

* Operational dashboards
* SLO/SLA monitoring
* Incident trend analysis

---

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ flink/
â”‚   â””â”€â”€ incident_aggregator.py
â”‚
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ alert_aggregations.py
â”‚   â””â”€â”€ escalation_aggregations.py
â”‚
â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ producers.py
â”‚
â”œâ”€â”€ README.md
```

---

## âš™ï¸ Kafka Topics

| Topic Name             | Description                            |
| ---------------------- | -------------------------------------- |
| `incident_alerts`      | Raw incident alerts                    |
| `incident_escalations` | Escalated incidents generated by Flink |

---

## âœ… Key Streaming Concepts Demonstrated

* Event-time vs processing-time
* Tumbling & sliding windows
* Watermarks & late event handling
* Stateful stream processing
* Kafka-based stream decoupling
* Fault tolerance with checkpointing

---

## ğŸš€ How to Run (High-Level)

1. Start Kafka (Confluent or Apache)
2. Produce alert events to `incident_alerts`
3. Run Flink job:

   ```bash
   python flink/incident_aggregator.py
   ```
4. Run Spark streaming jobs:

   ```bash
   spark-submit spark/alert_aggregations.py
   spark-submit spark/escalation_aggregations.py
   ```

---

## ğŸ¯ Use Cases

* Real-time incident detection
* Service reliability monitoring
* Alert fatigue reduction
* Observability pipelines
* SRE / DevOps analytics platforms
